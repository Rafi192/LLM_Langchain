{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2373f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8142707",
   "metadata": {},
   "source": [
    "Using Gemini flash-2.5 model using langChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c101a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm doing great, thanks for asking! I'd love to help you find the perfect outfit for your meeting. To give you the best suggestions, I need a little more information. Tell me about:\n",
      "\n",
      "**1. The Nature of the Meeting & Industry:**\n",
      "\n",
      "*   **What kind of meeting is it?** (e.g., formal client pitch, internal team discussion, networking event, job interview, creative brainstorm, a quick catch-up with colleagues)\n",
      "*   **What industry are you in?** (e.g., tech, finance, fashion, creative, healthcare, education, non-profit, government) This heavily influences the expected dress code.\n",
      "*   **What is your role/position?** (e.g., senior executive, junior associate, freelancer, entrepreneur)\n",
      "\n",
      "**2. The Vibe/Culture of the Company:**\n",
      "\n",
      "*   **Is it a very corporate, traditional environment, or more modern and laid-back?**\n",
      "*   **Do people typically dress in suits, business casual, or more smart casual?**\n",
      "*   **Is there a specific dress code already in place (even if unwritten)?**\n",
      "\n",
      "**3. Your Personal Style & Preferences:**\n",
      "\n",
      "*   **What do you generally feel comfortable and confident wearing?**\n",
      "*   **Are there any colors, fabrics, or styles you particularly like or dislike?**\n",
      "*   **Do you prefer dresses, skirts, pants, jumpsuits, etc.?**\n",
      "\n",
      "**4. The Time of Day & Location:**\n",
      "\n",
      "*   **Is it a morning, afternoon, or evening meeting?**\n",
      "*   **Where is the meeting taking place?** (e.g., their office, your office, a coffee shop, a restaurant, a conference room, virtual?)\n",
      "*   **What's the weather like where you are?**\n",
      "\n",
      "**5. Any Specific Goals for the Outfit?**\n",
      "\n",
      "*   **Do you want to project authority, creativity, approachability, trustworthiness, innovation?**\n",
      "\n",
      "Once I have a better understanding of these points, I can give you some really tailored and effective suggestions!\n"
     ]
    }
   ],
   "source": [
    "#gemini using openrouter- no langchain\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI   # OpenAI-compatible client works with OpenRouter\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n",
    "API_KEY = os.getenv(\"gemini_open_router\")\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "  base_url=\"https://openrouter.ai/api/v1\",\n",
    "  api_key=API_KEY,\n",
    "\n",
    ")\n",
    "response = client.chat.completions.create(\n",
    "    model=\"google/gemini-2.5-flash\",\n",
    "    messages=[\n",
    "        { \"role\": \"system\", \"content\": \"You are a dress expert. sugges me some outift ideas.\"},\n",
    "           { \"role\": \"user\", \"content\": \"hi how are you , I am going to a meeting\"}\n",
    "    ],\n",
    "    max_tokens=500,\n",
    ")\n",
    "print(response.choices[0].message.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45155feb",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'ChatModel' from 'langchain.chat_models' (c:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\gemini\\gemini_env\\Lib\\site-packages\\langchain\\chat_models\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mos\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdotenv\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_dotenv\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mchat_models\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ChatModel\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mschema\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage, SystemMessage\n\u001b[32m      8\u001b[39m memory = ConversationBufferMemory(memory_key=\u001b[33m\"\u001b[39m\u001b[33mchat_history\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'ChatModel' from 'langchain.chat_models' (c:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\gemini\\gemini_env\\Lib\\site-packages\\langchain\\chat_models\\__init__.py)"
     ]
    }
   ],
   "source": [
    "#using langchain with gemini\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain.chat_models import ChatModel\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
    "print(\"Memory imported successfully\")\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n",
    "API_KEY = os.getenv(\"gemini_open_router\")\n",
    "\n",
    "llm = ChatModel.from_api_key(\n",
    "    model_name=\"google/gemini-2.5-flash\",\n",
    "    openai_api_key=API_KEY,\n",
    "    openai_api_base=\"https://openrouter.ai/api/v1\",\n",
    "    temperature=0.5,\n",
    "    max_tokens=512,\n",
    ")\n",
    "print(llm)\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a helpful assistant.\"),\n",
    "    HumanMessage(content=\"Explain the theory of relativity in simple terms.\"),\n",
    "]\n",
    "response = llm(messages)\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76bc4999",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
