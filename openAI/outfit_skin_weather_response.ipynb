{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9a6a58d",
   "metadata": {},
   "source": [
    "So, firstly, I need to import the necesssary packages. load env variables. load openAI chat model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dde055e",
   "metadata": {},
   "source": [
    "Here, I will combine, Outfit attributes, skin tone, wether api data. \n",
    "and generate response based on the data using langChain-> Model, prompt, parsers, Chains and Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42144872",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dbf7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.schema.runnable import RunnableSequence\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2ca3c4b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasan\\AppData\\Local\\Temp\\ipykernel_5404\\722751171.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  chat = ChatOpenAI(\n"
     ]
    }
   ],
   "source": [
    "chat = ChatOpenAI(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"GPT_github_access_token\"),\n",
    "    openai_api_base=\"https://models.github.ai/inference\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1acc4c",
   "metadata": {},
   "source": [
    "Taking weathear API data and filering for specific data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81157004",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n",
    "API_KEY = os.getenv(\"weather_api_key\")\n",
    "BASE_URL = \"https://api.weatherapi.com/v1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68be4389",
   "metadata": {},
   "source": [
    "Current weather data for a specific city"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7ef8e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Fetch current weather for a given city.\n",
    "    Returns a human-readable summary.\n",
    "    \"\"\"\n",
    "    url = f\"{BASE_URL}/current.json?key={API_KEY}&q={city}&aqi=no\"\n",
    "    response = requests.get(url)\n",
    "    data = response.json()\n",
    "    \n",
    "    current = data.get(\"current\", {})\n",
    "    condition = current.get(\"condition\", {}).get(\"text\", \"Unknown\")\n",
    "    temp_c = current.get(\"temp_c\", \"Unknown\")\n",
    "    humidity = current.get(\"humidity\", \"Unknown\")\n",
    "    wind_kph = current.get(\"wind_kph\", \"Unknown\")\n",
    "    \n",
    "    \n",
    "    return f\"Current weather in {city}: {condition.lower()}, temperature around {temp_c}°C, humidity {humidity}%, wind speed {wind_kph} kph.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e77cc706",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Current weather in barcelona: clear, temperature around 14.1°C, humidity 51%, wind 16.6 kph.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_current_weather(\"barcelona\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6ee88",
   "metadata": {},
   "source": [
    "Forecast data-- for a specific city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6d674867",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateparser.search import search_dates\n",
    "import requests\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n",
    "API_KEY = os.getenv(\"weather_api_key\")\n",
    "BASE_URL = \"https://api.weatherapi.com/v1\"\n",
    "\n",
    "def get_forecast_weather(city: str, user_input: str) -> str:\n",
    "    # Extract date from input using search_dates\n",
    "    dates = search_dates(user_input, settings={'PREFER_DATES_FROM': 'future'})\n",
    "    if not dates:\n",
    "        return \"Could not determine the date. Please specify a valid date.\"\n",
    "    \n",
    "    date_obj = dates[0][1]\n",
    "    date_str = date_obj.strftime(\"%Y-%m-%d\")\n",
    "    \n",
    "    # Fetch forecast\n",
    "    url = f\"{BASE_URL}/forecast.json?key={API_KEY}&q={city}&dt={date_str}&aqi=no&alerts=no\"\n",
    "    data = requests.get(url).json()\n",
    "    \n",
    "    forecast_day = data.get(\"forecast\", {}).get(\"forecastday\", [{}])[0].get(\"day\", {})\n",
    "    condition = forecast_day.get(\"condition\", {}).get(\"text\", \"Unknown\")\n",
    "    avg_temp = forecast_day.get(\"avgtemp_c\", \"Unknown\")\n",
    "    max_temp = forecast_day.get(\"maxtemp_c\", \"Unknown\")\n",
    "    min_temp = forecast_day.get(\"mintemp_c\", \"Unknown\")\n",
    "    chance_of_rain = forecast_day.get(\"daily_chance_of_rain\", \"Unknown\")\n",
    "    wind_kph = forecast_day.get(\"maxwind_kph\", \"Unknown\")\n",
    "\n",
    "    \n",
    "    return (\n",
    "        f\"Forecast for {city} on {date_str}: {condition.lower()}, \"\n",
    "        f\"avg temp around {avg_temp}°C (min {min_temp}°C / max {max_temp}°C), \"\n",
    "        f\"chance of rain {chance_of_rain}%.\"\n",
    "        f\"Max wind speed of the day {wind_kph} kph\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0a4fe1ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forecast for New York on 2025-10-28: partly cloudy , avg temp around 7.9°C (min 5.3°C / max 11.4°C), chance of rain 0%.Max wind speed of the day 15.5 kph\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Current weather in new York: clear, temperature around 9.4°C, humidity 66%, wind 13.0 kph.'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(get_forecast_weather(\"New York\", \" on 28th October\"))\n",
    "get_current_weather(\"new York\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfcd09f3",
   "metadata": {},
   "source": [
    "Taking data from outfit extraction api "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "93ccf24a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'attributes': {'additional_details': 'lapel collar, button closure, pockets', 'clothing_type': 'coat', 'color': 'pink', 'pattern': 'solid', 'sleeve_length': 'long', 'style': 'casual'}, 'success': True}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "outfit_api = \"http://127.0.0.1:5000/api/extract_outfit\"\n",
    "\n",
    "image_path = r\"C:\\Users\\hasan\\Rafi_SAA\\Mobile_app_Cvindal1\\PROJECT_CVINDAL1\\test_img\\pink_coat.jpg\"\n",
    "\n",
    "with open(image_path, \"rb\") as f:\n",
    "    files = {\"image\": f}\n",
    "    response = requests.post(outfit_api, files= files)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    # print(\"API output\", data)\n",
    "    print(data)\n",
    "\n",
    "else:\n",
    "    print(\"error\", response.status_code, response.text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae941a2a",
   "metadata": {},
   "source": [
    "--------------------------------------------------------------------------------------\n",
    "\n",
    "Now utilizing LangCHain with memory, passing all the data into my gpt-4o model. \\\n",
    "\n",
    "\n",
    "================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38279094",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "conversation = ConversationChain(\n",
    "\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
