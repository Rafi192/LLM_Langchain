{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e6d2dec0",
   "metadata": {},
   "source": [
    "-------------------\n",
    "LangChain--> Memory Outline\n",
    "1. ConversationBufferMemory\n",
    "2. ConversationBufferWindowMemory\n",
    "3. ConversationTokenBufferMemory\n",
    "4. ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6257c761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc9729c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "340d6a5e",
   "metadata": {},
   "source": [
    "using converstaion buffer memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f01aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df7ed1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.chat_models import ChatOpenAI\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "load_dotenv(dotenv_path=r\"C:\\Users\\hasan\\Rafi_SAA\\python_practices\\LLM_Langchain\\llm_openai\\.env\")\n",
    "\n",
    "chat = ChatOpenAI(\n",
    "    model=\"openai/gpt-4o\",\n",
    "    openai_api_key=os.getenv(\"GPT_github_access_token\"),\n",
    "    openai_api_base=\"https://models.github.ai/inference\"\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf866be",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4b346fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasan\\AppData\\Local\\Temp\\ipykernel_18212\\1756075459.py:2: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory()\n",
      "C:\\Users\\hasan\\AppData\\Local\\Temp\\ipykernel_18212\\1756075459.py:3: LangChainDeprecationWarning: The class `ConversationChain` was deprecated in LangChain 0.2.7 and will be removed in 1.0. Use :class:`~langchain_core.runnables.history.RunnableWithMessageHistory` instead.\n",
      "  conversation = ConversationChain(\n"
     ]
    }
   ],
   "source": [
    "# llm = ChatOpenAI(temperature=0.0, model=chat)\n",
    "memory = ConversationBufferMemory()\n",
    "conversation = ConversationChain(\n",
    "    llm=chat, \n",
    "    memory = memory,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d97a6853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "\n",
      "Human: Hi there!\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! It's so nice to chat with you. How can I brighten your day or help with something?\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"Hi there!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ee9fad5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! It's so nice to chat with you. How can I brighten your day or help with something?\n",
      "Human: my name is Rafi. I love to play football. and I am a sofware engineer.\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi, Rafi! It's awesome to meet you. Football is such a thrilling sport—do you play as a forward, defender, midfielder, or goalkeeper? Or do you enjoy playing casually with friends? As for being a software engineer, that’s incredible! It must be exciting (and sometimes challenging, I imagine) to solve problems and build amazing things with code. What kind of projects or programming languages are you most into right now?\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"my name is Rafi. I love to play football. and I am a sofware engineer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dccb9e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! It's so nice to chat with you. How can I brighten your day or help with something?\n",
      "Human: my name is Rafi. I love to play football. and I am a sofware engineer.\n",
      "AI: Hi, Rafi! It's awesome to meet you. Football is such a thrilling sport—do you play as a forward, defender, midfielder, or goalkeeper? Or do you enjoy playing casually with friends? As for being a software engineer, that’s incredible! It must be exciting (and sometimes challenging, I imagine) to solve problems and build amazing things with code. What kind of projects or programming languages are you most into right now?\n",
      "Human: do you remember my name?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Of course, Rafi! You just told me your name, and I’ll be sure to remember it for the duration of our conversation. So, Rafi, what’s on your mind? Football strategies, coding challenges, or something else entirely?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"do you remember my name?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a882078e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3mThe following is a friendly conversation between a human and an AI. The AI is talkative and provides lots of specific details from its context. If the AI does not know the answer to a question, it truthfully says it does not know.\n",
      "\n",
      "Current conversation:\n",
      "Human: Hi there!\n",
      "AI: Hello! It's so nice to chat with you. How can I brighten your day or help with something?\n",
      "Human: my name is Rafi. I love to play football. and I am a sofware engineer.\n",
      "AI: Hi, Rafi! It's awesome to meet you. Football is such a thrilling sport—do you play as a forward, defender, midfielder, or goalkeeper? Or do you enjoy playing casually with friends? As for being a software engineer, that’s incredible! It must be exciting (and sometimes challenging, I imagine) to solve problems and build amazing things with code. What kind of projects or programming languages are you most into right now?\n",
      "Human: do you remember my name?\n",
      "AI: Of course, Rafi! You just told me your name, and I’ll be sure to remember it for the duration of our conversation. So, Rafi, what’s on your mind? Football strategies, coding challenges, or something else entirely?\n",
      "Human: how long can you remember? in terms of this converstaion buffer memory?\n",
      "AI:\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Great question, Rafi! My memory during this conversation works in the form of a context or buffer memory, meaning I can recall everything we\\'ve talked about so far as long as we’re still actively chatting. Once our conversation ends, I\\'ll essentially start fresh if you reach out again later. So, for the duration of this chat, I can remember all the details you share—your name, love for football, software engineering, and anything else we discuss—as part of this conversation\\'s \"short-term memory.\" Does that make sense?'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversation.predict(input=\"how long can you remember? in terms of this converstaion buffer memory?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87e1a7cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi there!\\nAI: Hello! It\\'s so nice to chat with you. How can I brighten your day or help with something?\\nHuman: my name is Rafi. I love to play football. and I am a sofware engineer.\\nAI: Hi, Rafi! It\\'s awesome to meet you. Football is such a thrilling sport—do you play as a forward, defender, midfielder, or goalkeeper? Or do you enjoy playing casually with friends? As for being a software engineer, that’s incredible! It must be exciting (and sometimes challenging, I imagine) to solve problems and build amazing things with code. What kind of projects or programming languages are you most into right now?\\nHuman: do you remember my name?\\nAI: Of course, Rafi! You just told me your name, and I’ll be sure to remember it for the duration of our conversation. So, Rafi, what’s on your mind? Football strategies, coding challenges, or something else entirely?\\nHuman: how long can you remember? in terms of this converstaion buffer memory?\\nAI: Great question, Rafi! My memory during this conversation works in the form of a context or buffer memory, meaning I can recall everything we\\'ve talked about so far as long as we’re still actively chatting. Once our conversation ends, I\\'ll essentially start fresh if you reach out again later. So, for the duration of this chat, I can remember all the details you share—your name, love for football, software engineering, and anything else we discuss—as part of this conversation\\'s \"short-term memory.\" Does that make sense?'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbbfcbff",
   "metadata": {},
   "source": [
    "Manually saving memory context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "69a70ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.save_context({\"input\": \"Hi\"}, \n",
    "                    {\"output\": \"What's up\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "013db4ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'history': 'Human: Hi there!\\nAI: Hello! It\\'s so nice to chat with you. How can I brighten your day or help with something?\\nHuman: my name is Rafi. I love to play football. and I am a sofware engineer.\\nAI: Hi, Rafi! It\\'s awesome to meet you. Football is such a thrilling sport—do you play as a forward, defender, midfielder, or goalkeeper? Or do you enjoy playing casually with friends? As for being a software engineer, that’s incredible! It must be exciting (and sometimes challenging, I imagine) to solve problems and build amazing things with code. What kind of projects or programming languages are you most into right now?\\nHuman: do you remember my name?\\nAI: Of course, Rafi! You just told me your name, and I’ll be sure to remember it for the duration of our conversation. So, Rafi, what’s on your mind? Football strategies, coding challenges, or something else entirely?\\nHuman: how long can you remember? in terms of this converstaion buffer memory?\\nAI: Great question, Rafi! My memory during this conversation works in the form of a context or buffer memory, meaning I can recall everything we\\'ve talked about so far as long as we’re still actively chatting. Once our conversation ends, I\\'ll essentially start fresh if you reach out again later. So, for the duration of this chat, I can remember all the details you share—your name, love for football, software engineering, and anything else we discuss—as part of this conversation\\'s \"short-term memory.\" Does that make sense?\\nHuman: Hi\\nAI: What\\'s up'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db9fd96",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4116bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_openai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
